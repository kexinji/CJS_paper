W = blockMatrixDiagonal(Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi)
dim(W)
W = do.call("rbind", replicate(n, Wi, simplify = F))
W.new = do.call("rbind", replicate(n, Wi, simplify = F))
dim(W.new)
?do.call
blockMatrixDiagonal
W = do.call("blockMatrixDiagonal", replicate(n, Wi, simplify = F))
dim(W)
W.old = blockMatrixDiagonal(Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi)
sum(W == W.old)
450^2
betaHat = function(lambda) {#
	invWx = solve(t(N) %*% W %*% N + lambda * K)#
	Wx = W - W %*% N %*% invWx %*% t(N) %*% W#
	betaHat = ginv(t(X) %*% Wx %*% X) %*% t(X) %*% Wx %*% Y#
	return(betaHat)#
}
betaHat(lambda)
fHat = function(lambda) {#
	invWf = solve(t(X) %*% W %*% X) #
	Wf = W - W %*% X %*% invWf %*% t(X) %*% W #
	fHat = ginv(t(N) %*% Wf %*% N + lambda * K) %*% t(N) %*% Wf %*% Y#
	return(fHat)#
}
invC = function(lambda) {#
	# The 1st row of block matrix C#
	C11 = t(X) %*% W %*% X#
	C12 = t(X) %*% W %*% N#
	CRow1 = cbind(C11, C12)#
#
	# The 2nd row of block matrix C#
 	C21 = t(N) %*% W %*% X#
	C22 = t(N) %*% W %*% N + lambda * K#
	CRow2 = cbind(C21, C22)#
#
	# Inverse of coefficient matrix#
	C = rbind(CRow1, CRow2)#
	invC = ginv(C)#
	return(invC)#
}
# Matrix chi in P*#
chi = cbind(X, N)#
#
# Matrix P*#
Pstar = function (lambda) {#
	invC = invC(lambda)#
	Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W#
	return(Pstar)#
}
dim(Bstar)
betaHat = betaHat(lambda)#
		fHat = fHat(lambda)#
		Pstar = Pstar(lambda)
score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)
lambda
fisher.scoring = function(lambda0, eps = 0.001) {#
	lambda = lambda0#
	diff = 1#
	while(diff > eps) {#
		lambda.old = lambda #
		betaHat = betaHat(lambda)#
		fHat = fHat(lambda)#
		Pstar = Pstar(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		diff = abs(lambda - lambda.old)#
	}#
	list(lambda)#
}
fisher.scoring(lambda)
betaHat
betaHat = function(lambda) {#
	invWx = solve(t(N) %*% W %*% N + lambda * K)#
	Wx = W - W %*% N %*% invWx %*% t(N) %*% W#
	betaHat = ginv(t(X) %*% Wx %*% X) %*% t(X) %*% Wx %*% Y#
	return(betaHat)#
}
betaHat(lambda)
fisher.scoring(lambda)
fHat = function(lambda) {#
	invWf = solve(t(X) %*% W %*% X) #
	Wf = W - W %*% X %*% invWf %*% t(X) %*% W #
	fHat = ginv(t(N) %*% Wf %*% N + lambda * K) %*% t(N) %*% Wf %*% Y#
	return(fHat)#
}
fHat(lambda)
Pstar = function (lambda) {#
	invC = invC(lambda)#
	Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W#
	return(Pstar)#
}
Pstar(lambda)
fisher.scoring = function(lambda0, eps = 0.001) {#
	lambda = lambda0#
	diff = 1#
	while(diff > eps) {#
		lambda.old = lambda #
		betaHat = betaHat(lambda)#
		fHat = fHat(lambda)#
		Pstar = Pstar(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		diff = abs(lambda - lambda.old)#
	}#
	list(lambda)#
}
fisher.scoring(lambda)
lambda
fisher.scoring = function(lambda0, eps = 0.01) {#
	lambda = lambda0#
	diff = 1#
	while(diff > eps) {#
		lambda.old = lambda #
		betaHat = betaHat(lambda)#
		fHat = fHat(lambda)#
		Pstar = Pstar(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		diff = abs(lambda - lambda.old)#
	}#
	list(lambda)#
}
fisher.scoring(lambda)
lambda = 5
fisher.scoring(lambda)
lambda
betaHat = betaHat(lambda)#
		fHat = fHat(lambda)#
		Pstar = Pstar(lambda)
score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)
info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))
lambda = as.numeric(lambda + solve(info)*score)
lambda
lambda.old = lambda #
		betaHat = betaHat(lambda)#
		fHat = fHat(lambda)#
		Pstar = Pstar(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)
dim(betaHAt)
dim(betaHat)
dim(fHat)
Pst = function (lambda) {#
	invC = invC(lambda)#
	Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W#
	return(Pstar)#
}
f.est = function(lambda) {#
	invWf = solve(t(X) %*% W %*% X) #
	Wf = W - W %*% X %*% invWf %*% t(X) %*% W #
	fHat = ginv(t(N) %*% Wf %*% N + lambda * K) %*% t(N) %*% Wf %*% Y#
	return(fHat)#
}
beta.est = function(lambda) {#
	invWx = solve(t(N) %*% W %*% N + lambda * K)#
	Wx = W - W %*% N %*% invWx %*% t(N) %*% W#
	betaHat = ginv(t(X) %*% Wx %*% X) %*% t(X) %*% Wx %*% Y#
	return(betaHat)#
}
betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)
score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)
lambda
betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)
lambda
betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)
lambda
betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		lambda
fisher.scoring = function(lambda0, eps = 0.01) {#
	lambda = lambda0#
	diff = 1#
	while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		lambda#
		diff = abs(lambda - lambda.old)#
	}#
	list(lambda)#
}
fisher.scoring(lambda)
lambda
lambda = 10
lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		lambda
lambda = 20
lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		lambda
eps = 0.01
diff = 1
20.25364 - 20.24393
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
lambda
eps
eps = 0.001
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
eps
eps = 0.005
diff
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
diff
betaHat
fHat
score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)
info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))
lambda = as.numeric(lambda + solve(info)*score)
lambda.old = lambda
diff = abs(lambda - lambda.old)
diff
lambda
betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)
lambda
26.63515 - 26.6274
eps
eps = 0.0007
diff = 26.63515 - 26.6274
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
lambda
eps
eps = 0.007
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
lambda
betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)
lambda
30.28352 - 30.27648
eps
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
lambda
lambda.old = lambda
lambda.old
lambda
betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = Pst(lambda)#
#
		# Score function#
		score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t((Y - X %*% betaHat - N %*% fHat)) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
		# information matrix #
		info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
		lambda = as.numeric(lambda + solve(info)*score)
lambda
diff = abs(lambda - lambda.old)
diff
scoreFunction = function(lambda) {#
	Pstar = PstarFunction(lambda)#
	score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t(Y - X %*% betaHat - N %*% fHat) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
	return(score)#
}
scoreFunction(lambda)
PstarFunction = function (lambda) {#
	invC = invC(lambda)#
	Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W#
	return(Pstar)#
}
scoreFunction(lambda)
# Zhang et al 2000#
#
n = 30 # number of subjects#
#tp = 30 # 15 time points for one period; 30 time points for two periods#
tp = 15 # one period first#
#
#==============================================================================#
# Simulate response Y first#
#==============================================================================#
#
# periodic function with period length equal to 30 days#
# use the cyclic spline, alternatively; and see what I can do..#
t = seq(1, 30, by = 2) # 60 for two periods, 30 for one period.#
f = 5*sin((2*pi/30)*t)#
# plot(t, f, type = "l")#
#
# independent random intercepts; sigma.b > sigma; n = 30; random time effect corresponding to different subject; #
sigma.b = 1.5 # variance for bi#
bi = rnorm(n, 0, sigma.b) #
#
# noise #
sigma = 0.8 # variance for epsilon#
eps.vec = rnorm(n*tp, 0, sigma)#
epsilon = matrix(eps.vec, n, tp)#
#
# OU process, assuming mean 0 and variance 1^2/2*2 = 1/4.#
# now let the variance function depend on t; let xi_0, xi_ = 1; #
# Use stationary OU process first. #
library(sde) #
# xi0 = 0.01#
# xi1 = 0.02#
# xi2 = 0.03#
# sigma.ou = exp(xi0 + xi1*t + xi2*t^2)#
theta2 = 2#
theta3 = 0.5#
tempU = rsOU(n*tp, theta=c(0, theta2, theta3))#
u = matrix(tempU, n, tp)#
# simulate covariate ages of the women#
# the average age of menopause is 51 years old.#
#set.seed(51)#
ageTemp = sample(35:60, size = n, replace = T)#
age = rep(ageTemp, each = tp)#
#
id = rep(1:n, each = tp)#
day = rep(t, n)#
#
# Will not take log here; as the data are already Normally simulated.#
beta0 = 27.05 # initiation of beta0#
beta1 = -0.5 # initiation of beta1#
tempResponse = matrix(rep(0, n*tp), n, tp)#
for(i in 1:n) {#
	# each row is one subject#
	tempResponse[i,] = beta0 + beta1*ageTemp[i] + f + bi[i] + u[i,] + epsilon[i,]#
}#
Y = as.vector(t(tempResponse))#
range(Y)#
Y = round(Y)#
Y = as.matrix(Y)
one = rep(1, n*tp)#
#
# X is of dimension n*tp \cross 2, since there are only two predictors. #
# X = cbind(one, age)#
X = cbind(rep(1, n*tp), rep(ageTemp, each = tp))
Zi = as.matrix(rep(1, tp))#
Zi.trans = t(rep(1, tp))#
Gammai = matrix(rep(0, tp*tp), tp, tp)#
for (i in 1:15) {#
	for (j in 1:15) {#
		Gammai[i,j] = (theta3^2 / (2*theta2)) * exp(-theta2*abs(2*(i-j)))#
	}#
}#
Vi = Zi %*% sigma.b %*% Zi.trans + sigma * diag(tp) + Gammai#
#
Wi = solve(Vi)#
#
# from internet http://www.r-bloggers.com/block-diagonal-matrices-in-r/#
# builds a block matrix whose diagonals are the square matrices provided.#
# m1=matrix(runif(10*10),nrow=10,ncol=10)#
# m2=matrix(runif(5*5),nrow=5,ncol=5)#
# blockMatrix<-blockMatrixDiagonal(m1,m2,m2,m1)#
# or#
# blockMatrix<-blockMatrixDiagonal(list(m1,m2,m2,m1))#
# C.Ladroue#
blockMatrixDiagonal<-function(...){  #
  matrixList<-list(...)#
  if(is.list(matrixList[[1]])) matrixList<-matrixList[[1]]#
  dimensions<-sapply(matrixList,FUN=function(x) dim(x)[1])#
  finalDimension<-sum(dimensions)#
  finalMatrix<-matrix(0,nrow=finalDimension,ncol=finalDimension)#
  index<-1#
  for(k in 1:length(dimensions)){#
    finalMatrix[index:(index+dimensions[k]-1),index:(index+dimensions[k]-1)]<-matrixList[[k]]#
    index<-index+dimensions[k]#
    }#
    finalMatrix#
  }#
# W = blockMatrixDiagonal(Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi)#
#
# Simpler code.#
W = do.call("blockMatrixDiagonal", replicate(n, Wi, simplify = F))
Ni = diag(1, 15, 15) #
#
# N = rbind(Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni)#
# The above is the naive way. The below is simpler way.#
# Stack Ni for n subjects.#
N = do.call("rbind", replicate(n, Ni, simplify = F))#
#
#==============================================================================#
# Smoothing matrix K - nonnegative definite, Green & Silverman (1994)#
# K does not depend on simulation#
#==============================================================================#
#
# Define matrix Q, double checked.#
Q = matrix(0, tp, tp-2)#
for(j in 1:(tp-2)) {#
	Q[j, j] = 1/2#
	Q[j + 1, j] = -1#
	Q[j + 2, j] = 1/2#
#
}#
#
# Define matrix R #
R = matrix(0, tp-2, tp-2)#
for (i in 1:(tp-2)) {#
	R[i, i] = (1/3)*4#
}#
#
for (i in 1:(tp-3)) {#
	R[i, i + 1] = (1/6)*2#
	R[i + 1, i] = (1/6)*2#
}#
#
# Check whether R is strictly positive definite#
#
# library(matrixcalc)#
# is.positive.definite(R) # True. #
# Define matrix K#
K = Q %*% ginv(R) %*% t(Q)#
# K = Q %*% solve(R) %*% t(Q); Use ginv() instead of solve() for inverse matrix.
beta.est = function(lambda) {#
	invWx = solve(t(N) %*% W %*% N + lambda * K)#
	Wx = W - W %*% N %*% invWx %*% t(N) %*% W#
	betaHat = ginv(t(X) %*% Wx %*% X) %*% t(X) %*% Wx %*% Y#
	return(betaHat)#
}#
#
#==============================================================================#
# f hat #
# Depend on both simulation and lambda.#
#==============================================================================#
f.est = function(lambda) {#
	invWf = solve(t(X) %*% W %*% X) #
	Wf = W - W %*% X %*% invWf %*% t(X) %*% W #
	fHat = ginv(t(N) %*% Wf %*% N + lambda * K) %*% t(N) %*% Wf %*% Y#
	return(fHat)#
}
#==============================================================================#
# Matrix C#
#==============================================================================#
# Inverse of Coefficient matrix #
#
invC = function(lambda) {#
	# The 1st row of block matrix C#
	C11 = t(X) %*% W %*% X#
	C12 = t(X) %*% W %*% N#
	CRow1 = cbind(C11, C12)#
#
	# The 2nd row of block matrix C#
 	C21 = t(N) %*% W %*% X#
	C22 = t(N) %*% W %*% N + lambda * K#
	CRow2 = cbind(C21, C22)#
#
	# Inverse of coefficient matrix#
	C = rbind(CRow1, CRow2)#
	invC = ginv(C)#
	return(invC)#
}
#==============================================================================#
# Matrix P*#
#==============================================================================#
#
# Matrix chi in P*#
chi = cbind(X, N)#
#
# Matrix P*#
PstarFunction = function (lambda) {#
	invC = invC(lambda)#
	Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W#
	return(Pstar)#
}
# Use option pivot = T for sparse matrix#
LTranspose = chol(K, pivot = T, LDL = T) # upper triangular matrix#
L = t(LTranspose) # lower triangular matrix#
# Matrix B#
B = L %*% ginv((t(L) %*% L))#
#
# Matrix Bstar#
Bstar = N %*% B
?chol
?eigen
eigen(K)
eigen(K)$values
dim(Bstar)
# To use tr() for trace of a function#
library(psych)#
#
# score function#
#
scoreFunction = function(lambda) {#
	Pstar = PstarFunction(lambda)#
	score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t(Y - X %*% betaHat - N %*% fHat) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
	return(score)#
}#
# information matrix #
infoFunction = function(lambda) {#
	Pstar = PstarFunction(lambda)#
	info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
	return(info)#
}
lambda
lambda = 30
lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = PstarFunction(lambda)#
		score = scoreFunction(lambda) 	# score function#
		info = infoFunction(lambda)		# information matrix #
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)
diff
lambda
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = PstarFunction(lambda)#
		score = scoreFunction(lambda) 	# score function#
		info = infoFunction(lambda)		# information matrix #
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)
}
eps = 0.007
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = PstarFunction(lambda)#
		score = scoreFunction(lambda) 	# score function#
		info = infoFunction(lambda)		# information matrix #
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)
}
# Zhang et al 2000#
#
n = 30 # number of subjects#
#tp = 30 # 15 time points for one period; 30 time points for two periods#
tp = 15 # one period first#
#
#==============================================================================#
# Simulate response Y first#
#==============================================================================#
#
# periodic function with period length equal to 30 days#
# use the cyclic spline, alternatively; and see what I can do..#
t = seq(1, 30, by = 2) # 60 for two periods, 30 for one period.#
f = 5*sin((2*pi/30)*t)#
# plot(t, f, type = "l")#
#
# independent random intercepts; sigma.b > sigma; n = 30; random time effect corresponding to different subject; #
sigma.b = 1.5 # variance for bi#
bi = rnorm(n, 0, sigma.b) #
#
# noise #
sigma = 0.8 # variance for epsilon#
eps.vec = rnorm(n*tp, 0, sigma)#
epsilon = matrix(eps.vec, n, tp)#
#
# OU process, assuming mean 0 and variance 1^2/2*2 = 1/4.#
# now let the variance function depend on t; let xi_0, xi_ = 1; #
# Use stationary OU process first. #
library(sde) #
# xi0 = 0.01#
# xi1 = 0.02#
# xi2 = 0.03#
# sigma.ou = exp(xi0 + xi1*t + xi2*t^2)#
theta2 = 2#
theta3 = 0.5#
tempU = rsOU(n*tp, theta=c(0, theta2, theta3))#
u = matrix(tempU, n, tp)#
# simulate covariate ages of the women#
# the average age of menopause is 51 years old.#
#set.seed(51)#
ageTemp = sample(35:60, size = n, replace = T)#
age = rep(ageTemp, each = tp)#
#
id = rep(1:n, each = tp)#
day = rep(t, n)#
#
# Will not take log here; as the data are already Normally simulated.#
beta0 = 27.05 # initiation of beta0#
beta1 = -0.5 # initiation of beta1#
tempResponse = matrix(rep(0, n*tp), n, tp)#
for(i in 1:n) {#
	# each row is one subject#
	tempResponse[i,] = beta0 + beta1*ageTemp[i] + f + bi[i] + u[i,] + epsilon[i,]#
}#
Y = as.vector(t(tempResponse))#
range(Y)#
Y = round(Y)#
Y = as.matrix(Y)#
# # plot of the response - verify that the response is indeed cyclic#
# for (i in 1:n) {#
	# plot(t, tempResponse[i,], type = "l", xlab = "day", ylim = c(-10, 20), ylab = "")#
	# par(new = TRUE)#
# }#
#==============================================================================#
# Covariate matrix X#
#==============================================================================#
#
one = rep(1, n*tp)#
#
# X is of dimension n*tp \cross 2, since there are only two predictors. #
# X = cbind(one, age)#
X = cbind(rep(1, n*tp), rep(ageTemp, each = tp))#
#==============================================================================#
# Cov matrix V#
#==============================================================================#
#
Zi = as.matrix(rep(1, tp))#
Zi.trans = t(rep(1, tp))#
Gammai = matrix(rep(0, tp*tp), tp, tp)#
for (i in 1:15) {#
	for (j in 1:15) {#
		Gammai[i,j] = (theta3^2 / (2*theta2)) * exp(-theta2*abs(2*(i-j)))#
	}#
}#
Vi = Zi %*% sigma.b %*% Zi.trans + sigma * diag(tp) + Gammai#
#
Wi = solve(Vi)#
#
# from internet http://www.r-bloggers.com/block-diagonal-matrices-in-r/#
# builds a block matrix whose diagonals are the square matrices provided.#
# m1=matrix(runif(10*10),nrow=10,ncol=10)#
# m2=matrix(runif(5*5),nrow=5,ncol=5)#
# blockMatrix<-blockMatrixDiagonal(m1,m2,m2,m1)#
# or#
# blockMatrix<-blockMatrixDiagonal(list(m1,m2,m2,m1))#
# C.Ladroue#
blockMatrixDiagonal<-function(...){  #
  matrixList<-list(...)#
  if(is.list(matrixList[[1]])) matrixList<-matrixList[[1]]#
  dimensions<-sapply(matrixList,FUN=function(x) dim(x)[1])#
  finalDimension<-sum(dimensions)#
  finalMatrix<-matrix(0,nrow=finalDimension,ncol=finalDimension)#
  index<-1#
  for(k in 1:length(dimensions)){#
    finalMatrix[index:(index+dimensions[k]-1),index:(index+dimensions[k]-1)]<-matrixList[[k]]#
    index<-index+dimensions[k]#
    }#
    finalMatrix#
  }#
# W = blockMatrixDiagonal(Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi)#
#
# Simpler code.#
W = do.call("blockMatrixDiagonal", replicate(n, Wi, simplify = F))#
#
#==============================================================================#
# Incidence matrix N#
# N does not depend on simulation#
#==============================================================================#
#
Ni = diag(1, 15, 15) #
#
# N = rbind(Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni)#
# The above is the naive way. The below is simpler way.#
# Stack Ni for n subjects.#
N = do.call("rbind", replicate(n, Ni, simplify = F))#
#
#==============================================================================#
# Smoothing matrix K - nonnegative definite, Green & Silverman (1994)#
# K does not depend on simulation#
#==============================================================================#
#
# Define matrix Q, double checked.#
Q = matrix(0, tp, tp-2)#
for(j in 1:(tp-2)) {#
	Q[j, j] = 1/2#
	Q[j + 1, j] = -1#
	Q[j + 2, j] = 1/2#
#
}#
#
# Define matrix R #
R = matrix(0, tp-2, tp-2)#
for (i in 1:(tp-2)) {#
	R[i, i] = (1/3)*4#
}#
#
for (i in 1:(tp-3)) {#
	R[i, i + 1] = (1/6)*2#
	R[i + 1, i] = (1/6)*2#
}#
#
# Check whether R is strictly positive definite#
#
# library(matrixcalc)#
# is.positive.definite(R) # True. #
# Define matrix K#
K = Q %*% ginv(R) %*% t(Q)#
# K = Q %*% solve(R) %*% t(Q); Use ginv() instead of solve() for inverse matrix.#
#==============================================================================#
# The MPLE estimates of beta and f #
#==============================================================================#
#==============================================================================#
# beta hat#
# Depend on both simulation and lambda.#
#==============================================================================#
beta.est = function(lambda) {#
	invWx = solve(t(N) %*% W %*% N + lambda * K)#
	Wx = W - W %*% N %*% invWx %*% t(N) %*% W#
	betaHat = ginv(t(X) %*% Wx %*% X) %*% t(X) %*% Wx %*% Y#
	return(betaHat)#
}#
#
#==============================================================================#
# f hat #
# Depend on both simulation and lambda.#
#==============================================================================#
f.est = function(lambda) {#
	invWf = solve(t(X) %*% W %*% X) #
	Wf = W - W %*% X %*% invWf %*% t(X) %*% W #
	fHat = ginv(t(N) %*% Wf %*% N + lambda * K) %*% t(N) %*% Wf %*% Y#
	return(fHat)#
}#
# # Check whether matrix ginv(t(N) %*% Wf %*% N + lambda * K) is positive definite#
# > is.positive.definite(ginv(t(N) %*% Wf %*% N + lambda * K))#
# Error in is.positive.definite(ginv(t(N) %*% Wf %*% N + lambda * K)) : #
  # argument x is not a symmetric matrix#
# > isSymmetric(ginv(t(N) %*% Wf %*% N + lambda * K))#
# [1] TRUE#
#
# > is.symmetric.matrix(ginv(t(N) %*% Wf %*% N + lambda * K))#
# [1] FALSE#
#
# # Reasons for the contradicitons - the tolerance is different.#
#==============================================================================#
# Estimation of lambda and variance components #
#==============================================================================#
#
#==============================================================================#
# Matrix C#
#==============================================================================#
# Inverse of Coefficient matrix #
#
invC = function(lambda) {#
	# The 1st row of block matrix C#
	C11 = t(X) %*% W %*% X#
	C12 = t(X) %*% W %*% N#
	CRow1 = cbind(C11, C12)#
#
	# The 2nd row of block matrix C#
 	C21 = t(N) %*% W %*% X#
	C22 = t(N) %*% W %*% N + lambda * K#
	CRow2 = cbind(C21, C22)#
#
	# Inverse of coefficient matrix#
	C = rbind(CRow1, CRow2)#
	invC = ginv(C)#
	return(invC)#
}#
# # Check whether matrix [X, NT] is of full rank.#
# # This is a necessary and sufficient condition for C to be positive definite.#
# oneT = rep(1, tp)#
# T = cbind(1, t)#
# Xstar = cbind(X, N %*% T)#
#
# # Rank of Xstar#
# rankMatrix(Xstar)#
#
# Alternatively, can use qr(Xstar)$rank #
# rank = 3; full rank = 4#
#==============================================================================#
# Matrix P*#
#==============================================================================#
#
# Matrix chi in P*#
chi = cbind(X, N)#
#
# Matrix P*#
PstarFunction = function (lambda) {#
	invC = invC(lambda)#
	Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W#
	return(Pstar)#
}#
#==============================================================================#
# Matrix B*#
# Does not depend on simulation or lambda#
#==============================================================================#
#
# Cholesky decomposition of K to obtain matrix L#
# Matrix L is tp * (tp - 2) rull-rank matrix#
#
#> chol(K)#
#Error in chol.default(K) : #
#  the leading minor of order 15 is not positive definite#
#
# Use option pivot = T for sparse matrix#
LTranspose = chol(K, pivot = T, LDL = T) # upper triangular matrix#
L = t(LTranspose) # lower triangular matrix#
# Matrix B#
B = L %*% ginv((t(L) %*% L))#
#
# Matrix Bstar#
Bstar = N %*% B#
#==============================================================================#
# Fisher scoring algorithm for tau and theta#
#==============================================================================#
#
# To use tr() for trace of a function#
library(psych)#
#
# score function#
#
scoreFunction = function(lambda) {#
	Pstar = PstarFunction(lambda)#
	score = -(1/2) * tr(Pstar %*% Bstar %*% t(Bstar)) + (1/2)*t(Y - X %*% betaHat - N %*% fHat) %*% W %*% Bstar %*% t(Bstar) %*% W %*% (Y - X %*% betaHat - N %*% fHat)#
	return(score)#
}#
# information matrix #
infoFunction = function(lambda) {#
	Pstar = PstarFunction(lambda)#
	info = (1/2) * tr(Pstar %*% Bstar %*% t(Bstar) %*% Pstar %*% Bstar %*% t(Bstar))#
	return(info)#
}
lambda = 5
eps = 0.01
diff = 1
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = PstarFunction(lambda)#
		score = scoreFunction(lambda) 	# score function#
		info = infoFunction(lambda)		# information matrix #
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
lambda
diff
lambda = 20
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = PstarFunction(lambda)#
		score = scoreFunction(lambda) 	# score function#
		info = infoFunction(lambda)		# information matrix #
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
lambda
diff
eps = 0.009
while(diff > eps) {#
		lambda.old = lambda #
		betaHat = beta.est(lambda)#
		fHat = f.est(lambda)#
		Pstar = PstarFunction(lambda)#
		score = scoreFunction(lambda) 	# score function#
		info = infoFunction(lambda)		# information matrix #
		lambda = as.numeric(lambda + solve(info)*score)#
		# lambda#
		diff = abs(lambda - lambda.old)#
	}
lambda
diff
betaHat
# Zhang et al 2000#
#
n = 30 # number of subjects#
#tp = 30 # 15 time points for one period; 30 time points for two periods#
tp = 15 # one period first#
#
#==============================================================================#
# Simulate response Y first#
#==============================================================================#
#
# periodic function with period length equal to 30 days#
# use the cyclic spline, alternatively; and see what I can do..#
t = seq(1, 30, by = 2) # 60 for two periods, 30 for one period.#
f = 5*sin((2*pi/30)*t)
a
a =4.56
round(a)
?replicate
ageTemp = sample(35:60, size = n, replace = T)
ageTemp
length(ageTemp)
cbind(rep(1, n*tp), rep(ageTemp, each = tp))
n = 30 # number of subjects#
#tp = 30 # 15 time points for one period; 30 time points for two periods#
tp = 15 # one period first#
# Initialization of variance parameters#
sigma.b = 1.5 # variance for bi#
sigma = 0.8 # variance for epsilon#
library(sde) #
# xi0 = 0.01#
# xi1 = 0.02#
# xi2 = 0.03#
# sigma.ou = exp(xi0 + xi1*t + xi2*t^2)#
theta2 = 2#
theta3 = 0.5#
#
# Initialization of regression coefficients#
beta0 = 27.05 # initiation of beta0#
beta1 = -0.5 # initiation of beta1#
#
id = rep(1:n, each = tp)#
day = rep(t, n)#
#
# Non-parametric function - periodic function with period length equal to 30 days#
# use the cyclic spline, alternatively; and see what I can do..#
t = seq(1, 30, by = 2) # 60 for two periods, 30 for one period.#
f = 5*sin((2*pi/30)*t)#
# plot(t, f, type = "l")#
#==============================================================================#
# Smoothing matrix K - nonnegative definite, Green & Silverman (1994)#
# K does not depend on simulation#
#==============================================================================#
#
# Define matrix Q, double checked.#
Q = matrix(0, tp, tp-2)#
for(j in 1:(tp-2)) {#
	Q[j, j] = 1/2#
	Q[j + 1, j] = -1#
	Q[j + 2, j] = 1/2#
#
}#
#
# Define matrix R #
R = matrix(0, tp-2, tp-2)#
for (i in 1:(tp-2)) {#
	R[i, i] = (1/3)*4#
}#
#
for (i in 1:(tp-3)) {#
	R[i, i + 1] = (1/6)*2#
	R[i + 1, i] = (1/6)*2#
}#
#
# Check whether R is strictly positive definite#
#
# library(matrixcalc)#
# is.positive.definite(R) # True. #
# Define matrix K. Use ginv() instead of solve() for inverse matrix.#
K = Q %*% ginv(R) %*% t(Q)#
#
#==============================================================================#
# Incidence matrix N#
# N does not depend on simulation#
#==============================================================================#
#
Ni = diag(1, tp, tp) #
#
# N = rbind(Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni)#
# The above is the naive way. The below is simpler way.#
# Stack Ni for n subjects.#
N = do.call("rbind", replicate(n, Ni, simplify = F))
Zi = as.matrix(rep(1, tp))#
Zi.trans = t(rep(1, tp))#
Gammai = matrix(rep(0, tp*tp), tp, tp)#
for (i in 1:15) {#
	for (j in 1:15) {#
		Gammai[i,j] = (theta3^2 / (2*theta2)) * exp(-theta2*abs(2*(i-j)))#
	}#
}#
Vi = Zi %*% sigma.b %*% Zi.trans + sigma * diag(tp) + Gammai#
#
Wi = solve(Vi)#
#
# from internet http://www.r-bloggers.com/block-diagonal-matrices-in-r/#
# builds a block matrix whose diagonals are the square matrices provided.#
# m1=matrix(runif(10*10),nrow=10,ncol=10)#
# m2=matrix(runif(5*5),nrow=5,ncol=5)#
# blockMatrix<-blockMatrixDiagonal(m1,m2,m2,m1)#
# or#
# blockMatrix<-blockMatrixDiagonal(list(m1,m2,m2,m1))#
# C.Ladroue#
blockMatrixDiagonal<-function(...){  #
  matrixList<-list(...)#
  if(is.list(matrixList[[1]])) matrixList<-matrixList[[1]]#
  dimensions<-sapply(matrixList,FUN=function(x) dim(x)[1])#
  finalDimension<-sum(dimensions)#
  finalMatrix<-matrix(0,nrow=finalDimension,ncol=finalDimension)#
  index<-1#
  for(k in 1:length(dimensions)){#
    finalMatrix[index:(index+dimensions[k]-1),index:(index+dimensions[k]-1)]<-matrixList[[k]]#
    index<-index+dimensions[k]#
    }#
    finalMatrix#
  }#
# W = blockMatrixDiagonal(Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi)#
#
# Simpler code.#
W = do.call("blockMatrixDiagonal", replicate(n, Wi, simplify = F))
#==============================================================================#
# beta hat#
# Depend on both simulation and lambda.#
#==============================================================================#
beta.est = function(lambda) {#
	invWx = solve(t(N) %*% W %*% N + lambda * K)#
	Wx = W - W %*% N %*% invWx %*% t(N) %*% W#
	betaHat = ginv(t(X) %*% Wx %*% X) %*% t(X) %*% Wx %*% Y#
	return(betaHat)#
}#
#
#==============================================================================#
# f hat #
# Depend on both simulation and lambda.#
#==============================================================================#
f.est = function(lambda) {#
	invWf = solve(t(X) %*% W %*% X) #
	Wf = W - W %*% X %*% invWf %*% t(X) %*% W #
	fHat = ginv(t(N) %*% Wf %*% N + lambda * K) %*% t(N) %*% Wf %*% Y#
	return(fHat)#
}
bi = rnorm(n, 0, sigma.b) #
		eps.vec = rnorm(n*tp, 0, sigma)#
		epsilon = matrix(eps.vec, n, tp)#
		tempU = rsOU(n*tp, theta=c(0, theta2, theta3))#
		u = matrix(tempU, n, tp)#
		age = sample(35:60, size = n, replace = T)#
		tempResponse = matrix(rep(0, n*tp), n, tp)#
		for(i in 1:n) {#
			# each row is one subject#
			tempResponse[i,] = beta0 + beta1*age[i] + f + bi[i] + u[i,] + epsilon[i,]#
		}#
		Y = as.vector(t(tempResponse))#
		Y = as.matrix(round(Y))#
		X =	cbind(rep(1, n*tp), rep(age, each = tp))
beta.est
beta.est(lambda)
lambda = 22
beta.est(lambda)
f.est(lambda)
dim(beta.est(lambda))
beta
# Number of simulation#
sim = 500 #
#
beta = matrix(0, 2, sim)#
fhat = matrix(0, 15, sim)
for (i in 1:sim) {#
		# independent random intercepts; sigma.b > sigma; random time effect corresponding to different subject;#
		bi = rnorm(n, 0, sigma.b) #
		eps.vec = rnorm(n*tp, 0, sigma)#
		epsilon = matrix(eps.vec, n, tp)#
		tempU = rsOU(n*tp, theta=c(0, theta2, theta3))#
		u = matrix(tempU, n, tp)#
		age = sample(35:60, size = n, replace = T)#
		tempResponse = matrix(rep(0, n*tp), n, tp)#
		for(i in 1:n) {#
			# each row is one subject#
			tempResponse[i,] = beta0 + beta1*age[i] + f + bi[i] + u[i,] + epsilon[i,]#
		}#
		Y = as.vector(t(tempResponse))#
		Y = as.matrix(round(Y))#
		X =	cbind(rep(1, n*tp), rep(age, each = tp))	#
 		beta[,i] = beta.est(lambda)#
 		f[,i] = f.est(lambda)#
	}
dim(f.est(lambda))
for (i in 1:sim) {#
		# independent random intercepts; sigma.b > sigma; random time effect corresponding to different subject;#
		bi = rnorm(n, 0, sigma.b) #
		eps.vec = rnorm(n*tp, 0, sigma)#
		epsilon = matrix(eps.vec, n, tp)#
		tempU = rsOU(n*tp, theta=c(0, theta2, theta3))#
		u = matrix(tempU, n, tp)#
		age = sample(35:60, size = n, replace = T)#
		tempResponse = matrix(rep(0, n*tp), n, tp)#
		for(i in 1:n) {#
			# each row is one subject#
			tempResponse[i,] = beta0 + beta1*age[i] + f + bi[i] + u[i,] + epsilon[i,]#
		}#
		Y = as.vector(t(tempResponse))#
		Y = as.matrix(round(Y))#
		X =	cbind(rep(1, n*tp), rep(age, each = tp))	#
 		beta[,i] = beta.est(lambda)#
 		fhat[,i] = f.est(lambda)#
	}
sim = 100 #
#
beta = matrix(0, 2, sim)#
fhat = matrix(0, 15, sim)
for (i in 1:sim) {#
		# independent random intercepts; sigma.b > sigma; random time effect corresponding to different subject;#
		bi = rnorm(n, 0, sigma.b) #
		eps.vec = rnorm(n*tp, 0, sigma)#
		epsilon = matrix(eps.vec, n, tp)#
		tempU = rsOU(n*tp, theta=c(0, theta2, theta3))#
		u = matrix(tempU, n, tp)#
		age = sample(35:60, size = n, replace = T)#
		tempResponse = matrix(rep(0, n*tp), n, tp)#
		for(i in 1:n) {#
			# each row is one subject#
			tempResponse[i,] = beta0 + beta1*age[i] + f + bi[i] + u[i,] + epsilon[i,]#
		}#
		Y = as.vector(t(tempResponse))#
		Y = as.matrix(round(Y))#
		X =	cbind(rep(1, n*tp), rep(age, each = tp))	#
 		beta[,i] = beta.est(lambda)#
 		fhat[,i] = f.est(lambda)#
	}
mean(beta[1, ])
mean(beta[2, ])
mean(fhat[1, ])
dim(f)
f[1,]
f
mean(fhat[2, ])
mean(fhat[3,])
mean(fhat[4,])
mean(fhat[5,])
mean(fhat[6,])
mean(fhat[7,])
mean(fhat[8,])
mean(fhat[9,])
mean(fhat[10,])
mean(fhat[11,])
mean(fhat[12,])
mean(fhat[13,])
mean(fhat[14,])
mean(fhat[15,])
beta.sim = matrix(0, 2, 1)#
f.sim = matrix(0, 15, 1)
simulation = function(n, sim, sigma.b, sigma, theta2, theta3, lambda) {#
	for (i in 1:sim) {#
		# independent random intercepts; sigma.b > sigma; random time effect corresponding to different subject;#
		bi = rnorm(n, 0, sigma.b) #
		eps.vec = rnorm(n*tp, 0, sigma)#
		epsilon = matrix(eps.vec, n, tp)#
		tempU = rsOU(n*tp, theta=c(0, theta2, theta3))#
		u = matrix(tempU, n, tp)#
		age = sample(35:60, size = n, replace = T)#
		tempResponse = matrix(rep(0, n*tp), n, tp)#
		for(i in 1:n) {#
			# each row is one subject#
			tempResponse[i,] = beta0 + beta1*age[i] + f + bi[i] + u[i,] + epsilon[i,]#
		}#
		Y = as.vector(t(tempResponse))#
		Y = as.matrix(round(Y))#
		X =	cbind(rep(1, n*tp), rep(age, each = tp))	#
 		beta[,i] = beta.est(lambda)#
 		fhat[,i] = f.est(lambda)#
	}#
	beta.sim[1, ] = mean(beta[1, ])#
	beta.sim[2, ] = mean(beta[2, ])#
	for (i in 1:tp) {#
		f.sim[i, ] = mean(fhat[i,])#
	}#
	return(beta.sim, f.sim)#
}
simulation(n, sim, sigma.b, sigma, theta2, theta3, lambda)
return(beta.sim)
# Simulations#
simulation = function(n, sim, sigma.b, sigma, theta2, theta3, lambda) {#
	for (i in 1:sim) {#
		# independent random intercepts; sigma.b > sigma; random time effect corresponding to different subject;#
		bi = rnorm(n, 0, sigma.b) #
		eps.vec = rnorm(n*tp, 0, sigma)#
		epsilon = matrix(eps.vec, n, tp)#
		tempU = rsOU(n*tp, theta=c(0, theta2, theta3))#
		u = matrix(tempU, n, tp)#
		age = sample(35:60, size = n, replace = T)#
		tempResponse = matrix(rep(0, n*tp), n, tp)#
		for(i in 1:n) {#
			# each row is one subject#
			tempResponse[i,] = beta0 + beta1*age[i] + f + bi[i] + u[i,] + epsilon[i,]#
		}#
		Y = as.vector(t(tempResponse))#
		Y = as.matrix(round(Y))#
		X =	cbind(rep(1, n*tp), rep(age, each = tp))	#
 		beta[,i] = beta.est(lambda)#
 		fhat[,i] = f.est(lambda)#
	}#
	beta.sim[1, ] = mean(beta[1, ])#
	beta.sim[2, ] = mean(beta[2, ])#
	for (i in 1:tp) {#
		f.sim[i, ] = mean(fhat[i,])#
	}#
	return(list(beta.sim, f.sim))#
}
simulation(n, sim, sigma.b, sigma, theta2, theta3, lambda)
f
simulation(n, sim, sigma.b, sigma, theta2, theta3, lambda)$[2]
simulation(n, sim, sigma.b, sigma, theta2, theta3, lambda)$[[2]]
simulation(n, sim, sigma.b, sigma, theta2, theta3, lambda)$f.sim
37.5/1.5
25*25
36/1.5
n = 30 # number of subjects#
#tp = 30 # 15 time points for one period; 30 time points for two periods#
tp = 15 # one period first#
# Initialization of variance parameters#
sigma.b = 1.5 # variance for bi#
sigma = 0.8 # variance for epsilon#
library(sde) #
# xi0 = 0.01#
# xi1 = 0.02#
# xi2 = 0.03#
# sigma.ou = exp(xi0 + xi1*t + xi2*t^2)#
theta2 = 2#
theta3 = 0.5#
lambda = 22#
#
# Initialization of regression coefficients#
beta0 = 27.05 # initiation of beta0#
beta1 = -0.5 # initiation of beta1#
#
id = rep(1:n, each = tp)#
day = rep(t, n)
t
t = seq(1, 30, by = 2) # 60 for two periods, 30 for one period.#
f = 5*sin((2*pi/30)*t)#
# plot(t, f, type = "l")#
# Other covariates#
id = rep(1:n, each = tp)#
day = rep(t, n)
Define matrix Q, double checked.#
Q = matrix(0, tp, tp-2)#
for(j in 1:(tp-2)) {#
	Q[j, j] = 1/2#
	Q[j + 1, j] = -1#
	Q[j + 2, j] = 1/2#
#
}#
#
# Define matrix R #
R = matrix(0, tp-2, tp-2)#
for (i in 1:(tp-2)) {#
	R[i, i] = (1/3)*4#
}#
#
for (i in 1:(tp-3)) {#
	R[i, i + 1] = (1/6)*2#
	R[i + 1, i] = (1/6)*2#
}#
#
# Check whether R is strictly positive definite#
#
# library(matrixcalc)#
# is.positive.definite(R) # True. #
# Define matrix K. Use ginv() instead of solve() for inverse matrix.#
K = Q %*% ginv(R) %*% t(Q)
Ni = diag(1, tp, tp) #
#
# N = rbind(Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni, Ni)#
# The above is the naive way. The below is simpler way.#
# Stack Ni for n subjects.#
N = do.call("rbind", replicate(n, Ni, simplify = F))#
#
#==============================================================================#
# Covariance matrix V#
# Depend on parameter initialization.#
#==============================================================================#
#
Zi = as.matrix(rep(1, tp))#
Zi.trans = t(rep(1, tp))#
Gammai = matrix(rep(0, tp*tp), tp, tp)#
for (i in 1:15) {#
	for (j in 1:15) {#
		Gammai[i,j] = (theta3^2 / (2*theta2)) * exp(-theta2*abs(2*(i-j)))#
	}#
}#
Vi = Zi %*% sigma.b %*% Zi.trans + sigma * diag(tp) + Gammai#
#
Wi = solve(Vi)#
#
# from internet http://www.r-bloggers.com/block-diagonal-matrices-in-r/#
# builds a block matrix whose diagonals are the square matrices provided.#
# m1=matrix(runif(10*10),nrow=10,ncol=10)#
# m2=matrix(runif(5*5),nrow=5,ncol=5)#
# blockMatrix<-blockMatrixDiagonal(m1,m2,m2,m1)#
# or#
# blockMatrix<-blockMatrixDiagonal(list(m1,m2,m2,m1))#
# C.Ladroue#
blockMatrixDiagonal<-function(...){  #
  matrixList<-list(...)#
  if(is.list(matrixList[[1]])) matrixList<-matrixList[[1]]#
  dimensions<-sapply(matrixList,FUN=function(x) dim(x)[1])#
  finalDimension<-sum(dimensions)#
  finalMatrix<-matrix(0,nrow=finalDimension,ncol=finalDimension)#
  index<-1#
  for(k in 1:length(dimensions)){#
    finalMatrix[index:(index+dimensions[k]-1),index:(index+dimensions[k]-1)]<-matrixList[[k]]#
    index<-index+dimensions[k]#
    }#
    finalMatrix#
  }#
# W = blockMatrixDiagonal(Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi, Wi)#
#
# Simpler code.#
W = do.call("blockMatrixDiagonal", replicate(n, Wi, simplify = F))
beta.est = function(lambda) {#
	invWx = solve(t(N) %*% W %*% N + lambda * K)#
	Wx = W - W %*% N %*% invWx %*% t(N) %*% W#
	betaHat = ginv(t(X) %*% Wx %*% X) %*% t(X) %*% Wx %*% Y#
	return(betaHat)#
}#
#
#==============================================================================#
# f hat #
# Depend on both simulation and lambda.#
#==============================================================================#
f.est = function(lambda) {#
	invWf = solve(t(X) %*% W %*% X) #
	Wf = W - W %*% X %*% invWf %*% t(X) %*% W #
	fHat = ginv(t(N) %*% Wf %*% N + lambda * K) %*% t(N) %*% Wf %*% Y#
	return(fHat)#
}
f.est(lambda)
lambda
X
Zi = as.matrix(rep(1, tp))
Zi
dim(Zi)
Zi.trans = t(rep(1, tp))
Zi.trans
t(Zi)
tp
diag(tp)
age = sample(35:60, size = n, replace = T)
X =	cbind(rep(1, n*tp), rep(age, each = tp))
invC = function(lambda, X) {#
	# The 1st row of block matrix C#
	C11 = t(X) %*% W %*% X#
	C12 = t(X) %*% W %*% N#
	CRow1 = cbind(C11, C12)#
#
	# The 2nd row of block matrix C#
 	C21 = t(N) %*% W %*% X#
	C22 = t(N) %*% W %*% N + lambda * K#
	CRow2 = cbind(C21, C22)#
#
	# Inverse of coefficient matrix#
	C = rbind(CRow1, CRow2)#
	invC = ginv(C)#
	return(invC)#
}
invC(lambda, X)
beta.est(lambda)
# Matrix chi in P*#
chi = cbind(X, N)#
#
# Matrix P*#
PstarFunction = function (lambda) {#
	invC = invC(lambda)#
	Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W#
	return(Pstar)#
}
PstarFunction(lambda)
dim(X)
Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W
dim(chi)
dim(W)
dim(invC)
invC(lambda)
invC(lambda, X)
dim(invC(lambda, X))
# Matrix P*#
PstarFunction = function (lambda) {#
	invC = invC(lambda, X)#
	Pstar = W - W %*% chi %*% invC %*% t(chi) %*% W#
	return(Pstar)#
}
# Use option pivot = T for sparse matrix#
LTranspose = chol(K, pivot = T, LDL = T) # upper triangular matrix#
L = t(LTranspose) # lower triangular matrix#
# Matrix B#
B = L %*% ginv((t(L) %*% L))#
#
# Matrix Bstar#
Bstar = N %*% B
